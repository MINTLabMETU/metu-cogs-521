{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tutorial \n",
    "\n",
    "## Part-I\n",
    "\n",
    "In this live session, we will **(a)** read from a text file, **(b)** store data in intermediate structures, **(c)** traverse chunks of input, **(d)** eliminate trailing white spaces and stop words, and **(e)** write the processed data to an output file. Target language will be Turkish.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### * imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading file names in a directory\n",
    "import glob"
   ]
  },
  {
   "source": [
    "### ** globals"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./in/\"\n",
    "output_path = \"./out/\""
   ]
  },
  {
   "source": [
    "### (a-b) read input from files and store in a dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def read_and_store_input(input_path):\n",
    "    # initialize dictionary\n",
    "    data = {}\n",
    "    # read file names from the input directory\n",
    "    input_files = glob.glob(input_path+'mtdb/*.txt')\n",
    "    for file_path in input_files:\n",
    "        content = open(file_path, 'r')\n",
    "        # create an empty list with a key as the name of the current file\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        data[file_name]=[]\n",
    "        # populate the list with content from file\n",
    "        for line in content:\n",
    "            # check if line has content\n",
    "            if line.strip() != \"\":\n",
    "                data[file_name].append(line)\n",
    "    return data\n",
    "\n",
    "data = read_and_store_input(input_path)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### (c) traverse the content"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content of which files we have access to?\n",
    "for key in data:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# lets see the contents of a specific file, say '10370000.txt'\n",
    "# 20000 character limitation. last 20000 characters are displayed\n",
    "for index, line in enumerate(data['10370000.txt']):\n",
    "    print(\"LINE #%s: %s\" %(index,line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# too many white spaces, lets eliminate the excess\n",
    "for index, line in enumerate(data['10370000.txt']):\n",
    "    print(\"LINE #%s: %s\" %(index,line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets access to a specific line in a specific file\n",
    "# remember that lines with no content were excluded while reading from input files. indexes are not identical with the files'.\n",
    "file_name = '10370000.txt'\n",
    "line = 101\n",
    "print(\"LINE #%s from FILE '%s': %s\" %(line, file_name, data[file_name][line].strip()))"
   ]
  },
  {
   "source": [
    "### (d) eliminate trailing white spaces and stop words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# read stop words from a file into a list\n",
    "# taken from --> https://github.com/sgsinclair/trombone/blob/master/src/main/resources/org/voyanttools/trombone/keywords/stop.tr.turkish-lucene.txt\n",
    "stop_words = []\n",
    "for line in open(input_path+'stop_words', 'r'):\n",
    "    # check if not comment\n",
    "    if line[0] != '#':\n",
    "        stop_words.append(line.strip())\n",
    "\n",
    "# traverse the data\n",
    "for file, content in data.items():\n",
    "    for index, line in enumerate(content):\n",
    "        # eliminate trailing white spaces\n",
    "        line = line.strip() \n",
    "        # eliminate stop words\n",
    "        new_line = (' ').join(word for word in line.split() if word not in stop_words)\n",
    "        content[index] = new_line\n",
    "\n",
    "# lets compare\n",
    "for index, line in enumerate(data['10370000.txt']):\n",
    "    print(\"LINE #%s: %s\" %(index,line))\n"
   ]
  },
  {
   "source": [
    "### (e) export the preprocessed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name, content in data.items():\n",
    "    output_file = open(output_path+file_name, 'w')\n",
    "    for line in content:\n",
    "        output_file.write(line+'\\n')\n",
    "    output_file.close()"
   ]
  }
 ]
}